import sys
#### running from service-script ####
samples = glob_wildcards("staging/se_reads/{sample}.fastq.gz").sample
msg = 'snakefile command recieved - SINGLE END FASTQ PROCESSING 16s \n'
sys.stderr.write(msg)
configfile: "config.json"
database_path = config["params"]["database"]
save_classified = config["params"]["save_classified_sequences"]
save_unclassified = config["params"]["save_unclassified_sequences"]
confidence_interval = config["params"]["confidence_interval"]
ruleorder: fastqc_raw_reads > trim_adapters > fastqc_on_trimmed_read > classify_with_kraken


rule_all_list = [
        expand('output/{sample}/fastqc_results/raw_read/raw_{sample}_fastqc.html', sample=samples),
        expand('output/{sample}/trimmed_read/{sample}_trimmed.fastq.gz', sample=samples),
        expand('output/{sample}/fastqc_results/trimmed_read/{sample}_trimmed_fastqc.html', sample=samples),
        expand('output/{sample}/kraken_output/{sample}_k2_output.txt', sample=samples),
        ]

# update rule all according to saving the classified and unclassified sequences in the Kraken2 command
if save_classified == True:
    cf = "--classified-out"
    co = "{sample}_classified_reads.fastq"
    co_gz = "output/{sample}/kraken_output/{sample}_classified_reads.fastq.gz"
    rule_all_list.append(expand("output/{sample}/kraken_output/{sample}_classified_reads.fastq.gz", sample=samples))
    msg = "Adding save classified sequences to kraken2 command. \n"
    sys.stderr.write(msg)
else:
    cf = ""
    co = ""
    co_gz = ""

if save_unclassified == True:
    ucf = "--unclassified-out"
    uco = "{sample}_unclassified_reads.fastq"
    uco_gz = "output/{sample}/kraken_output/{sample}_unclassified_reads.fastq.gz"
    rule_all_list.append(expand("output/{sample}/kraken_output/{sample}_unclassified_reads.fastq.gz", sample=samples))
    msg = "Adding save unclassified sequences to kraken2 command. \n"
    sys.stderr.write(msg)
else:
    ucf = ""
    uco = ""
    uco_gz = ""


rule all:
    input:
        rule_all_list

rule fastqc_raw_reads:
    input:
        raw_read = 'staging/se_reads/{sample}.fastq.gz',
    params:
        fastqc_dir = 'output/{sample}/fastqc_results/raw_read',
        out = 'output'
    output:
        fastqc_html = 'output/{sample}/fastqc_results/raw_read/raw_{sample}_fastqc.html',
        fastqc_zip = 'output/{sample}/fastqc_results/raw_read/raw_{sample}_fastqc.zip'
    threads: 4
    shell:
        '''
        mkdir -p {params.fastqc_dir}

        fastqc --version
        
        fastqc {input.raw_read} \
        -t {threads} \
        -o {params.fastqc_dir} -q

        mv {params.fastqc_dir}/{wildcards.sample}_fastqc.html {output.fastqc_html}
        mv {params.fastqc_dir}/{wildcards.sample}_fastqc.zip {output.fastqc_zip}
        '''

rule trim_adapters:
    input:
        raw_read = 'staging/se_reads/{sample}.fastq.gz',
    params:
        out_dir = 'output/{sample}/trimmed_read/',
        tmp_name = 'output/{sample}/trimmed_read/{sample}_trimmed.fq.gz'
    output:
        trimmed_read = 'output/{sample}/trimmed_read/{sample}_trimmed.fastq.gz',
        trimming_report = 'output/{sample}/trimmed_read/{sample}.fastq.gz_trimming_report.txt'
    shell:
        '''
            mkdir -p {params.out_dir}
            trim_galore --gzip -o {params.out_dir} {input.raw_read}

            mv {params.tmp_name} {output.trimmed_read}
        '''

rule fastqc_on_trimmed_read:
    input:
        trimmed_read = 'output/{sample}/trimmed_read/{sample}_trimmed.fastq.gz',
    params:
        fastqc_dir = 'output/{sample}/fastqc_results/trimmed_read'
    output:
        fastqc_html = 'output/{sample}/fastqc_results/trimmed_read/{sample}_trimmed_fastqc.html',
        fastqc_zip = 'output/{sample}/fastqc_results/trimmed_read/{sample}_trimmed_fastqc.zip'
    threads: 4
    shell:
        '''
        mkdir -p {params.fastqc_dir}

        fastqc --version
        
        fastqc {input.trimmed_read} \
        -t {threads} \
        -o {params.fastqc_dir} -q
        '''


rule classify_with_kraken:
    input:
        kraken2_input = 'output/{sample}/trimmed_read/{sample}_trimmed.fastq.gz',
    params:
        database = database_path,
        kraken_dir = 'output/{sample}/kraken_output',
        classified_flag = cf,
        classified_fq = co,
        unclassified_flag = ucf,
        unclassified_fq = uco,
        ci = confidence_interval
    output:
        k2_output = 'output/{sample}/kraken_output/{sample}_k2_output.txt',
        k2report = 'output/{sample}/kraken_output/{sample}_k2_report.txt'
    threads: 16
    shell:
        '''
        mkdir -p {params.kraken_dir}

        kraken2 --db {params.database} \
            --threads {threads} \
            --minimum-hit-groups 3 \
            --report-minimizer-data \
            --memory-mapping \
            {params.classified_flag} \
            {params.classified_fq} \
            {params.unclassified_flag} \
            {params.unclassified_fq} \
            --report {output.k2report} \
            {input.kraken2_input} \
            --confidence {params.ci} \
            --output {output.k2_output}
        '''

rule zip_n_move_classified_reads:
    input:
        k2report = 'output/{sample}/kraken_output/{sample}_k2_report.txt'
    params:
        raw_classified = co
    output:
        zippped_classified = co_gz
    shell:
        '''
        gzip -c {params.raw_classified} > {output.zippped_classified}
        '''

rule zip_n_move_unclassified_reads:
    input:
        k2report = 'output/{sample}/kraken_output/{sample}_k2_report.txt'
    params:
        raw_unclassified = uco,
    output:
        zippped_unclassified = uco_gz
    shell:
        '''
        gzip -c {params.raw_unclassified} > {output.zippped_unclassified}
        '''